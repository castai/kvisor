controls: ""
version: gke-1.6.0
id: 3
text: Worker Nodes
type: node
groups:
    - id: "3.1"
      text: Worker Node Configuration Files
      checks:
        - id: 3.1.1
          text: Ensure that the proxy kubeconfig file permissions are set to 644 or more restrictive
          audit: '/bin/sh -c ''if test -e $proxykubeconfig; then stat -c permissions=%a $proxykubeconfig; fi'' '
          type: automated
          tests:
            test_items:
                - flag: permissions
                  compare:
                    op: bitmask
                    value: "644"
          remediation: |-
            Run the below command (based on the file location on your system) on each worker
            node. For example,
            ```
            chmod 644 <proxy kubeconfig file>
            ```
          scored: false
        - id: 3.1.2
          text: Ensure that the proxy kubeconfig file ownership is set to root:root
          audit: '/bin/sh -c ''if test -e $proxykubeconfig; then stat -c %U:%G $proxykubeconfig; fi'' '
          type: automated
          tests:
            test_items:
                - flag: root:root
          remediation: |-
            Run the below command (based on the file location on your system) on each worker node. For example,

            ```
            chown root:root <proxy kubeconfig file>
            ```
          scored: false
        - id: 3.1.3
          text: Ensure that the kubelet configuration file has permissions set to 600
          audit: '/bin/sh -c ''if test -e $kubeletconf; then stat -c permissions=%a $kubeletconf; fi'' '
          type: automated
          tests:
            test_items:
                - flag: permissions
                  compare:
                    op: bitmask
                    value: "644"
          remediation: |-
            Run the following command (using the kubelet config file location):

            ```
            chmod 600 <kubelet_config_file>
            ```
          scored: false
        - id: 3.1.4
          text: Ensure that the kubelet configuration file ownership is set to root:root
          audit: '/bin/sh -c ''if test -e $kubeletconf; then stat -c %U:%G $kubeletconf; fi'' '
          type: automated
          tests:
            test_items:
                - flag: root:root
          remediation: |-
            Run the following command (using the config file location identified in the Audit step):

            ```
            chown root:root <kubelet_config_file>
            ```
          scored: false
    - id: "3.2"
      text: Kubelet
      checks:
        - id: 3.2.1
          text: Ensure that the Anonymous Auth is Not Enabled
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
                - flag: --anonymous-auth
                  path: '{.authentication.anonymous.enabled}'
                  compare:
                    op: eq
                    value: "false"
          remediation: "**Remediation Method 1:**\n\nIf configuring via the Kubelet config file, you first need to locate the file.\n\nTo do this, SSH to each node and execute the following command to find the kubelet process:\n\n```\nps -ef | grep kubelet\n```\n\nThe output of the above command provides details of the active kubelet process, from which we can see the location of the configuration file provided to the kubelet service with the `--config` argument. The file can be viewed with a command such as `more` or `less`, like so:\n\n```\nsudo less /path/to/kubelet-config.json\n```\n\nDisable Anonymous Authentication by setting the following parameter:\n\n```\n\"authentication\": { \"anonymous\": { \"enabled\": false } }\n```\n\n**Remediation Method 2:**\n\nIf using executable arguments, edit the kubelet service file on each worker node and ensure the below parameters are part of the `KUBELET_ARGS` variable string.\n\nFor systems using `systemd`, such as the Amazon EKS Optimised Amazon Linux or Bottlerocket AMIs, then this file can be found at `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf`. Otherwise, you may need to look up documentation for your chosen operating system to determine which service manager is configured:\n\n```\n--anonymous-auth=false\n```\n\n**For Both Remediation Steps:**\n\nBased on your system, restart the `kubelet` service and check the service status. \n\nThe following example is for operating systems using `systemd`, such as the Amazon EKS Optimised Amazon Linux or Bottlerocket AMIs, and invokes the `systemctl` command. If `systemctl` is not available then you will need to look up documentation for your chosen operating system to determine which service manager is configured:\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n```"
          scored: true
        - id: 3.2.2
          text: Ensure that the --authorization-mode argument is not set to AlwaysAllow
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
                - flag: --authorization-mode
                  path: '{.authorization.mode}'
                  compare:
                    op: nothave
                    value: AlwaysAllow
          remediation: "**Remediation Method 1:**\n\nIf configuring via the Kubelet config file, you first need to locate the file.\n\nTo do this, SSH to each node and execute the following command to find the kubelet process:\n\n```\nps -ef | grep kubelet\n```\n\nThe output of the above command provides details of the active kubelet process, from which we can see the location of the configuration file provided to the kubelet service with the `--config` argument. The file can be viewed with a command such as `more` or `less`, like so:\n\n```\nsudo less /path/to/kubelet-config.json\n```\n\nEnable Webhook Authentication by setting the following parameter:\n\n```\n\"authentication\": { \"webhook\": { \"enabled\": true } }\n```\n\nNext, set the Authorization Mode to `Webhook` by setting the following parameter:\n\n```\n\"authorization\": { \"mode\": \"Webhook }\n```\n\nFiner detail of the `authentication` and `authorization` fields can be found in the [Kubelet Configuration documentation](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/).\n\n**Remediation Method 2:**\n\nIf using executable arguments, edit the kubelet service file on each worker node and ensure the below parameters are part of the `KUBELET_ARGS` variable string.\n\nFor systems using `systemd`, such as the Amazon EKS Optimised Amazon Linux or Bottlerocket AMIs, then this file can be found at `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf`. Otherwise, you may need to look up documentation for your chosen operating system to determine which service manager is configured:\n\n```\n--authentication-token-webhook\n--authorization-mode=Webhook\n```\n\n**For Both Remediation Steps:**\n\nBased on your system, restart the `kubelet` service and check the service status. \n\nThe following example is for operating systems using `systemd`, such as the Amazon EKS Optimised Amazon Linux or Bottlerocket AMIs, and invokes the `systemctl` command. If `systemctl` is not available then you will need to look up documentation for your chosen operating system to determine which service manager is configured:\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n```"
          scored: true
        - id: 3.2.3
          text: Ensure that a Client CA File is Configured
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
                - flag: --client-ca-file
                  path: '{.authentication.x509.clientCAFile}'
                  set: true
          remediation: "**Remediation Method 1:**\n\nIf configuring via the Kubelet config file, you first need to locate the file.\n\nTo do this, SSH to each node and execute the following command to find the kubelet process:\n\n```\nps -ef | grep kubelet\n```\n\nThe output of the above command provides details of the active kubelet process, from which we can see the location of the configuration file provided to the kubelet service with the `--config` argument. The file can be viewed with a command such as `more` or `less`, like so:\n\n```\nsudo less /path/to/kubelet-config.json\n```\n\nConfigure the client certificate authority file by setting the following parameter appropriately:\n\n```\n\"authentication\": { \"x509\": {\"clientCAFile\": <path/to/client-ca-file> } }\"\n```\n\n**Remediation Method 2:**\n\nIf using executable arguments, edit the kubelet service file on each worker node and ensure the below parameters are part of the `KUBELET_ARGS` variable string.\n\nFor systems using `systemd`, such as the Amazon EKS Optimised Amazon Linux or Bottlerocket AMIs, then this file can be found at `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf`. Otherwise, you may need to look up documentation for your chosen operating system to determine which service manager is configured:\n\n```\n--client-ca-file=<path/to/client-ca-file>\n```\n\n**For Both Remediation Steps:**\n\nBased on your system, restart the `kubelet` service and check the service status. \n\nThe following example is for operating systems using `systemd`, such as the Amazon EKS Optimised Amazon Linux or Bottlerocket AMIs, and invokes the `systemctl` command. If `systemctl` is not available then you will need to look up documentation for your chosen operating system to determine which service manager is configured:\n\n```\nsystemctl daemon-reload\nsystemctl restart kubelet.service\nsystemctl status kubelet -l\n```"
          scored: true
        - id: 3.2.4
          text: Ensure that the --read-only-port is disabled
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
                - flag: --read-only-port
                  path: '{.readOnlyPort}'
                  set: true
                  compare:
                    op: eq
                    value: "0"
          remediation: |-
            If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to 0

            ```
            "readOnlyPort": 0
            ```

            If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.

            ```
            --read-only-port=0
            ```

            For each remediation:
            Based on your system, restart the `kubelet` service and check status

            ```
            systemctl daemon-reload
            systemctl restart kubelet.service
            systemctl status kubelet -l
            ```
          scored: false
        - id: 3.2.5
          text: Ensure that the --streaming-connection-idle-timeout argument is not set to 0
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
                - flag: --streaming-connection-idle-timeout
                  path: '{.streamingConnectionIdleTimeout}'
                  compare:
                    op: noteq
                    value: "0"
                - flag: --streaming-connection-idle-timeout
                  path: '{.streamingConnectionIdleTimeout}'
                  set: false
            bin_op: or
          remediation: |-
            **Remediation Method 1:**

            If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet-config.yaml` and set the below parameter to a non-zero value in the format of #h#m#s

            ```
            "streamingConnectionIdleTimeout": "4h0m0s"
            ```

            You should ensure that the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` does not specify a `--streaming-connection-idle-timeout` argument because it would override the Kubelet config file.

            **Remediation Method 2:**

            If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.

            ```
            --streaming-connection-idle-timeout=4h0m0s
            ```

            **Remediation Method 3:**

            If using the api configz endpoint consider searching for the status of `"streamingConnectionIdleTimeout":` by extracting the live configuration from the nodes running kubelet.

            **See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes
            ```
            kubectl proxy --port=8001 &

            export HOSTNAME_PORT=localhost:8001 (example host and port number)
            export NODE_NAME=gke-cluster-1-pool1-5e572947-r2hg (example node name from "kubectl get nodes")

            curl -sSL "http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz"
            ```

            **For all three remediations:**
            Based on your system, restart the `kubelet` service and check status

            ```
            systemctl daemon-reload
            systemctl restart kubelet.service
            systemctl status kubelet -l
            ```
          scored: true
        - id: 3.2.6
          text: Ensure that the --make-iptables-util-chains argument is set to true
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
                - flag: --make-iptables-util-chains
                  path: '{.makeIPTablesUtilChains}'
                  compare:
                    op: eq
                    value: "true"
                - flag: --make-iptables-util-chains
                  path: '{.makeIPTablesUtilChains}'
                  set: false
            bin_op: or
          remediation: |-
            **Remediation Method 1:**

            If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet/kubelet-config.json` and set the below parameter to true

            ```
            "makeIPTablesUtilChains": true
            ```

            Ensure that `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` does not set the `--make-iptables-util-chains` argument because that would override your Kubelet config file.

            **Remediation Method 2:**

            If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.

            ```
            --make-iptables-util-chains:true
            ```

            **Remediation Method 3:**

            If using the api configz endpoint consider searching for the status of `"makeIPTablesUtilChains.: true` by extracting the live configuration from the nodes running kubelet.

            **See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes
            ```
            kubectl proxy --port=8001 &

            export HOSTNAME_PORT=localhost:8001 (example host and port number)
            export NODE_NAME=gke-cluster-1-pool1-5e572947-r2hg (example node name from "kubectl get nodes")

            curl -sSL "http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz"
            ```

            **For all three remediations:**
            Based on your system, restart the `kubelet` service and check status

            ```
            systemctl daemon-reload
            systemctl restart kubelet.service
            systemctl status kubelet -l
          scored: true
        - id: 3.2.7
          text: Ensure that the --eventRecordQPS argument is set to 0 or a level which ensures appropriate event capture
          type: "automated"
          audit: "/bin/ps -fC $kubeletbin"
          audit_config: "/bin/cat $kubeletconf"
          tests:
            test_items:
              - flag: --event-qps
                path: '{.eventRecordQPS}'
                set: true
                compare:
                  op: eq
                value: 0
          remediation: |-
            If using a Kubelet config file, edit the file to set `eventRecordQPS:` to an appropriate level.

            If using command line arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubeadm.conf` on each worker node and set the below parameter in `KUBELET_SYSTEM_PODS_ARGS` variable.

            Based on your system, restart the `kubelet` service. For example:

            ```
            systemctl daemon-reload
            systemctl restart kubelet.service
            ```
          scored: true
        - id: 3.2.8
          text: Ensure that the --rotate-certificates argument is not present or is set to true
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
              - flag: --rotate-certificates
                path: '{.rotateCertificates}'
                compare:
                  op: eq
                  value: true
              - flag: --rotate-certificates
                path: '{.rotateCertificates}'
                set: false
            bin_op: or
          remediation: |-
            **Remediation Method 1:**

            If modifying the Kubelet config file, edit the kubelet-config.yaml file `/etc/kubernetes/kubelet/kubelet-config.yaml` and set the below parameter to true

            ```
            "RotateCertificate":true
            ```

            Additionally, ensure that the kubelet service file /etc/systemd/system/kubelet.service.d/10-kubelet-args.conf does not set the --RotateCertificate executable argument to false because this would override the Kubelet config file.

            **Remediation Method 2:**

            If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.

            ```
            --RotateCertificate=true
            ```
          scored: true
        - id: 3.2.9
          text: Ensure that the RotateKubeletServerCertificate argument is set to true
          audit: /bin/ps -fC $kubeletbin
          audit_config: /bin/cat $kubeletconf
          type: automated
          tests:
            test_items:
              - flag: RotateKubeletServerCertificate
                path: '{.featureGates.RotateKubeletServerCertificate}'
                compare:
                  op: eq
                    value: true
          remediation: |-
            **Remediation Method 1:**

            If modifying the Kubelet config file, edit the kubelet-config.json file `/etc/kubernetes/kubelet-config.yaml` and set the below parameter to true

            ```
            "featureGates": {
             "RotateKubeletServerCertificate":true
            },
            ```

            Additionally, ensure that the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` does not set the `--rotate-kubelet-server-certificate` executable argument to false because this would override the Kubelet config file.

            **Remediation Method 2:**

            If using executable arguments, edit the kubelet service file `/etc/systemd/system/kubelet.service.d/10-kubelet-args.conf` on each worker node and add the below parameter at the end of the `KUBELET_ARGS` variable string.

            ```
            --rotate-kubelet-server-certificate=true
            ```

            **Remediation Method 3:**

            If using the api configz endpoint consider searching for the status of `"RotateKubeletServerCertificate":` by extracting the live configuration from the nodes running kubelet.

            **See detailed step-by-step configmap procedures in [Reconfigure a Node's Kubelet in a Live Cluster](https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/), and then rerun the curl statement from audit process to check for kubelet configuration changes
            ```
            kubectl proxy --port=8001 &

            export HOSTNAME_PORT=localhost:8001 (example host and port number)
            export NODE_NAME=gke-cluster-1-pool1-5e572947-r2hg (example node name from "kubectl get nodes")

            curl -sSL "http://${HOSTNAME_PORT}/api/v1/nodes/${NODE_NAME}/proxy/configz"
            ```

            **For all three remediation methods:**
            Restart the `kubelet` service and check status. The example below is for when using systemctl to manage services:

            ```
            systemctl daemon-reload
            systemctl restart kubelet.service
            systemctl status kubelet -l
            ```
          scored: true
